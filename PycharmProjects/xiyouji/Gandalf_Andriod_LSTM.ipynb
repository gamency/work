{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from master_lightsaber import lightsaber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# from utils.uilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'simplejson'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a01e780daa50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mruamel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYAML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mRohan\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCavalry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/xiyouji/Rohan/Cavalry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# import matplotlib.pyplot as plt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mRohan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecouple_Captcha\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mup_down_transf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mruamel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYAML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/xiyouji/Rohan/Decouple_Captcha.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msimplejson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'simplejson'"
     ]
    }
   ],
   "source": [
    "from ruamel.yaml import YAML\n",
    "from Rohan import Cavalry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommentedMap([('year', 2018),\n",
       "              ('start_month', 2),\n",
       "              ('end_month', 3),\n",
       "              ('start_day', 20),\n",
       "              ('end_day', 30),\n",
       "              ('PC_data_dir',\n",
       "               CommentedMap([('PC_first_dir', './Data/H/First/'),\n",
       "                             ('PC_second_dir', './Data/H/Second/')])),\n",
       "              ('Andriod_second_dir', './Data/A/Second/'),\n",
       "              ('Terminal', 0),\n",
       "              ('Scenario', [0, 1])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml = YAML()\n",
    "yaml_file = './Rohan/cavalry.yml'\n",
    "cav_info = open(yaml_file).read()\n",
    "cav = yaml.load(cav_info)\n",
    "cav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cav['start_month'] = 6\n",
    "cav['end_month'] = 6\n",
    "cav['start_day'] = 1\n",
    "cav['end_day'] = 30\n",
    "cav['custid'] = 'lavada_positive'\n",
    "# cav['custid'] = 'lavada_negative'\n",
    "cav['Andriod_second_dir'] = './Data/A/'\n",
    "cav['Terminal'] = 1\n",
    "cav['appName'] = 'lavada_ta'\n",
    "cav['test'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(yaml_file, \"w\") as f:\n",
    "    yaml.dump(cav,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yaml = YAML()\n",
    "# yaml_file = './Rohan/cavalry.yml'\n",
    "# cav_info = open(yaml_file).read()\n",
    "# cav = yaml.load(cav_info)\n",
    "# cav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data_info = [cav['year'], cav['start_month'], cav['end_month'], cav['start_day'], cav['end_day'], cav['PC_data_dir'],\n",
    "                  cav['Andriod_second_dir'], cav['Terminal'], cav['custid'], cav['appName'], cav['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = Cavalry.RohanCavlry(fetch_data_info, 'table_of_fetch', 'verification', 'captcha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-eab973f4d279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb1_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "b1_b, b2_b, local1, local2 = test.form()\n",
    "# b1_h, b2_h, local1, local2 = test.form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(b1_h), len(b2_h), len(local1), len(local2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mobile_hu = []\n",
    "for ind in range(0, len(b2_h)):\n",
    "    if b2_h[ind].loc[0, 'terminal'] == 1:\n",
    "        mobile_hu.append(b2_h[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agument data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b2_b = b2_b * 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in b2_h:\n",
    "    i.loc[0, 'Bot'] = 0\n",
    "for i in b2_b:\n",
    "    i.loc[0, 'Bot'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset, axis = 0)\n",
    "    sigma = np.std(dataset, axis = 0)\n",
    "    return (dataset - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_signal(data, window_size = 400):\n",
    "    segments = np.empty((0, window_size, 2))\n",
    "    \n",
    "    labels = np.empty((0))\n",
    "    \n",
    "    for ind in range(0, len(data)):\n",
    "        print(\"ind\", ind)\n",
    "        diff_size = window_size - len(data[ind].op_x)\n",
    "        if diff_size > 0:\n",
    "            sample = np.zeros((diff_size,), dtype = data[ind].op_x.dtypes) + 0.001\n",
    "            \n",
    "            seg_x = np.concatenate((np.array[data[ind].op_x], sample), axis = 0)\n",
    "            seg_y = np.concatenate((np.array[data[ind].op_y], sample), axis = 0)\n",
    "        else:\n",
    "            seg_x = data[ind].loc[0: window_size - 1, 'op_x']\n",
    "            seg_y = data[ind].loc[0: window_size - 1, 'op_y']\n",
    "        seg_x = feature_normalize(seg_x)\n",
    "        seg_y = feature_normalize(seg_y)\n",
    "        \n",
    "        segments = np.vstack([segments, np.dstack([seg_x, seg_y])])\n",
    "        \n",
    "        data[ind]['Bot'] = data[ind]['Bot'].astype(float)\n",
    "        Bot_prob = data[ind].loc[0, 'Bot']\n",
    "        \n",
    "        if data[ind].loc[0, 'scenario'] == 0:\n",
    "            if Bot_prob >= 0.69:\n",
    "                Bclass = 1\n",
    "            else:\n",
    "                Bclass = 0\n",
    "        elif data[ind].loc[0, 'scenario'] == 1:\n",
    "            if Bot_prob >= 0.58:\n",
    "                Bclass = 1\n",
    "            else:\n",
    "                Bclass = 0\n",
    "        else:\n",
    "            print(\"error happen here, check scenario value\")\n",
    "        labels = np.append(labels, Bclass)\n",
    "        \n",
    "    return segments, labels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 400\n",
    "channel = 2\n",
    "\n",
    "def transformer(data, window_size, channel):\n",
    "    segments, labels = segments_signal(data, window_size)\n",
    "    \n",
    "    labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "    reshape_segments = segments.reshape(len(segments), window_size, channel)\n",
    "    \n",
    "    return reshape_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = []\n",
    "training_set[0:0] = b2_h\n",
    "training_set[0:0] = b2_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_segments,training_set_labels = transformer(training_set, window_size, channel)\n",
    "print(\"transform testing set\")\n",
    "# training_set_segments,training_set_labels = transformer(training_set, window_size, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(training_set_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_segments[0:2, 0:1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(training_set_segments, training_set_labels, \n",
    "                                               stratify = training_set_labels,\n",
    "                                               random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lab_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(X_tr[0], len(lab_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lab_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define & train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 6\n",
    "lstm_layers = 2\n",
    "batch_size = 200\n",
    "seq_len = 400\n",
    "learning_rate = 0.0001\n",
    "epochs = 1000\n",
    "\n",
    "n_classes = 2\n",
    "n_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    with tf.device(\"/gpu:2\"):\n",
    "        inputs = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "        labels = tf.placeholder(tf.float32, [None, n_classes], name='labels')\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep')\n",
    "        learning_rate = tf.placeholder(tf.float32, name='learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.device(\"/gpu:2\"):\n",
    "        lstm_data_input = tf.transpose(inputs, [1, 0, 2])\n",
    "        lstm_in = tf.reshape(lstm_data_input, [-1, n_channels])\n",
    "        \n",
    "        lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None)\n",
    "        lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "        \n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([drop]* lstm_layers)\n",
    "        \n",
    "        initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.device(\"/gpu:2\"):\n",
    "        outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32, initial_state=initial_state)\n",
    "        \n",
    "        logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "        \n",
    "        y_ = tf.nn.softmax(logits, name='y_')\n",
    "        \n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "        \n",
    "        gradients = train_op.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "        optimizer = train_op.apply_gradients(capped_gradients)\n",
    "        \n",
    "        cor_pre = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(cor_pre, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICE=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICE\"] = \"0, 1, 2, 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "val_acc = []\n",
    "val_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for ec in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for x,y in get_batches(X_tr, lab_tr, batch_size):\n",
    "            feed = {inputs: x, labels: y, keep_prob: 0.5, initial_state: state, learning_rate: learning_rate}\n",
    "            \n",
    "            loss ,_ ,state, acc = sess.run([cost, optimizer, final_state, accuracy], feed_dict=feed)\n",
    "            \n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            if(iteration %5 == 0):\n",
    "                print(\"Epoch:{}/{}\".format(ec, epochs), \"Iteration:{:d}\".format(iteration), \"Train loss:{:.6f}\".format(loss, acc))\n",
    "                \n",
    "            if(iteration %25 == 0):\n",
    "                \n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc = []\n",
    "                val_loss = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_vld, lab_vld, batch_size):\n",
    "                    feed = {inputs: x_v, labels: y_v, keep_prob: 1.0, initial_state: val_state}\n",
    "                    \n",
    "                    loss_v ,state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict=feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                print(\"Epoch:{}/{}\".format(ec, epochs), \n",
    "                      \"Iteration:{:d}\".format(iteration),\n",
    "                      \"Validation loss:{:.6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc:{:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                val_acc.append(np.mean(val_acc_))\n",
    "                val_loss.append(np.mean(val_loss_))\n",
    "                \n",
    "            iteration += 1\n",
    "        saver.save(sess, \"checkpoints/gandalf_lstm.ckpt\")\n",
    "    saver.save(sess, \"checkpoints/gandalf_lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.arange(iteration - 1)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(val_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], np.array(val_acc), 'b*')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
