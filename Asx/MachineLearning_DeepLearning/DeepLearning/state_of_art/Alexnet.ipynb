{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_activations(t):\n",
    "    print(t.op.name, ' ', t.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "    parameters = []\n",
    "    \n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([11, 11, 3, 64],\n",
    "                                                dtype = tf.float32, stddev = 1e-1), name = 'weights')\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 4, 4, 1], padding ='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(bias, name = scope)\n",
    "        print_activations(conv1)\n",
    "        parameters += [kernel, biases]\n",
    "        \n",
    "        lrn1 = tf.nn.lrn(conv1, 4, bias=1.0, alpha=0.001/9,beta=0.75,name='lrn1')\n",
    "        pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "        print_activations(pool1)\n",
    "        \n",
    "    with tf.name_scope('conv2') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([5, 5, 64, 192],\n",
    "                                                dtype = tf.float32, stddev = 1e-1), name = 'weights')\n",
    "        conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding ='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[192], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(bias, name = scope)\n",
    "        print_activations(conv2)\n",
    "        parameters += [kernel, biases]\n",
    "        \n",
    "        lrn1 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001/9,beta=0.75,name='lrn1')\n",
    "        pool2 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "        print_activations(pool2)\n",
    "        \n",
    "    with tf.name_scope('conv3') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 192, 384],\n",
    "                                                dtype = tf.float32, stddev = 1e-1), name = 'weights')\n",
    "        conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding ='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[384], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv3 = tf.nn.relu(bias, name = scope)\n",
    "        print_activations(conv3)\n",
    "        parameters += [kernel, biases]\n",
    "        \n",
    "        #lrn1 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001/9,beta=0.75,name='lrn1')\n",
    "        #pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "        #print_activations(pool2)\n",
    "    with tf.name_scope('conv4') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 384, 256],\n",
    "                                                dtype = tf.float32, stddev = 1e-1), name = 'weights')\n",
    "        conv = tf.nn.conv2d(conv3, kernel, [1, 1, 1, 1], padding ='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv4 = tf.nn.relu(bias, name = scope)\n",
    "        print_activations(conv4)\n",
    "        parameters += [kernel, biases]\n",
    "\n",
    "    with tf.name_scope('conv5') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256],\n",
    "                                                dtype = tf.float32, stddev = 1e-1), name = 'weights')\n",
    "        conv = tf.nn.conv2d(conv4, kernel, [1, 1, 1, 1], padding ='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv5 = tf.nn.relu(bias, name = scope)\n",
    "        print_activations(conv5)\n",
    "        parameters += [kernel, biases]\n",
    "        \n",
    "    pool5 = tf.nn.max_pool(conv5, ksize = [1,3, 3, 1], strides = [1, 2, 2, 1],\n",
    "                          padding = 'VALID', name ='pool5')\n",
    "    print_activations(pool5)\n",
    "    \n",
    "    return pool5, parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_tensorflow_run(session, target, info_string):\n",
    "    num_steps_burn_in = 10\n",
    "    total_duration = 0.0\n",
    "    total_duration_squared = 0.0\n",
    "    \n",
    "    for i in range(num_batches + num_steps_burn_in):\n",
    "        start_time = time.time()\n",
    "        _ = session.run(target)\n",
    "        duration = time.time() - start_time\n",
    "        if i >= num_steps_burn_in:\n",
    "            if not i % 10:\n",
    "                print('%s: step %d, duration =%.3f'%(\n",
    "                datetime.now(), i - num_steps_burn_in, duration))\n",
    "            total_duration += duration\n",
    "            total_duration_squared += duration * duration\n",
    "        mn = total_duration / num_batches\n",
    "        vr = total_duration_squared / num_batches - mn * mn\n",
    "        sd = math.sqrt(vr)\n",
    "        print('%s: %s across %d steps, %.3f +/- %.3f sec / batch'%(\n",
    "        datetime.now(), info_string, num_batches, mn, sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_benchmark():\n",
    "    with tf.Graph().as_default():\n",
    "        image_size = 224\n",
    "        images = tf.Variable(tf.random_normal([batch_size,\n",
    "                                              image_size,\n",
    "                                              image_size, 3],\n",
    "                                             dtype = tf.float32,\n",
    "                                             stddev = 1e-1))\n",
    "        pool5, parameters = inference(images)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        \n",
    "        time_tensorflow_run(sess, pool5, \"Forward\")\n",
    "        \n",
    "        objective = tf.nn.l2_loss(pool5)\n",
    "        grad = tf.gradients(objective, parameters)\n",
    "        \n",
    "        time_tensorflow_run(sess, grad, \"Forward-backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1   [32, 56, 56, 64]\n",
      "conv1/pool1   [32, 27, 27, 64]\n",
      "conv2   [32, 27, 27, 192]\n",
      "conv2/pool2   [32, 13, 13, 192]\n",
      "conv3   [32, 13, 13, 384]\n",
      "conv4   [32, 13, 13, 256]\n",
      "conv5   [32, 13, 13, 256]\n",
      "pool5   [32, 6, 6, 256]\n",
      "2017-10-27 09:16:26.395056: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:28.097266: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:29.545573: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:31.119061: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:32.575986: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:34.004551: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:35.449939: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:36.911792: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:38.366429: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:39.939376: Forward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:16:41.368870: step 0, duration =1.429\n",
      "2017-10-27 09:16:41.369017: Forward across 100 steps, 0.014 +/- 0.142 sec / batch\n",
      "2017-10-27 09:16:43.027891: Forward across 100 steps, 0.031 +/- 0.217 sec / batch\n",
      "2017-10-27 09:16:45.222597: Forward across 100 steps, 0.053 +/- 0.305 sec / batch\n",
      "2017-10-27 09:16:47.209551: Forward across 100 steps, 0.073 +/- 0.361 sec / batch\n",
      "2017-10-27 09:16:48.962985: Forward across 100 steps, 0.090 +/- 0.398 sec / batch\n",
      "2017-10-27 09:16:50.926815: Forward across 100 steps, 0.110 +/- 0.439 sec / batch\n",
      "2017-10-27 09:16:52.666889: Forward across 100 steps, 0.127 +/- 0.468 sec / batch\n",
      "2017-10-27 09:16:54.349718: Forward across 100 steps, 0.144 +/- 0.493 sec / batch\n",
      "2017-10-27 09:16:55.977469: Forward across 100 steps, 0.160 +/- 0.514 sec / batch\n",
      "2017-10-27 09:16:57.539931: Forward across 100 steps, 0.176 +/- 0.532 sec / batch\n",
      "2017-10-27 09:16:59.151640: step 10, duration =1.612\n",
      "2017-10-27 09:16:59.151770: Forward across 100 steps, 0.192 +/- 0.551 sec / batch\n",
      "2017-10-27 09:17:00.858458: Forward across 100 steps, 0.209 +/- 0.571 sec / batch\n",
      "2017-10-27 09:17:02.821935: Forward across 100 steps, 0.229 +/- 0.596 sec / batch\n",
      "2017-10-27 09:17:04.414729: Forward across 100 steps, 0.245 +/- 0.611 sec / batch\n",
      "2017-10-27 09:17:05.976607: Forward across 100 steps, 0.260 +/- 0.624 sec / batch\n",
      "2017-10-27 09:17:07.554322: Forward across 100 steps, 0.276 +/- 0.637 sec / batch\n",
      "2017-10-27 09:17:09.050017: Forward across 100 steps, 0.291 +/- 0.648 sec / batch\n",
      "2017-10-27 09:17:10.600191: Forward across 100 steps, 0.307 +/- 0.660 sec / batch\n",
      "2017-10-27 09:17:12.061317: Forward across 100 steps, 0.321 +/- 0.669 sec / batch\n",
      "2017-10-27 09:17:13.516162: Forward across 100 steps, 0.336 +/- 0.677 sec / batch\n",
      "2017-10-27 09:17:15.091084: step 20, duration =1.575\n",
      "2017-10-27 09:17:15.091229: Forward across 100 steps, 0.351 +/- 0.688 sec / batch\n",
      "2017-10-27 09:17:16.564855: Forward across 100 steps, 0.366 +/- 0.696 sec / batch\n",
      "2017-10-27 09:17:18.125650: Forward across 100 steps, 0.382 +/- 0.705 sec / batch\n",
      "2017-10-27 09:17:19.771511: Forward across 100 steps, 0.398 +/- 0.715 sec / batch\n",
      "2017-10-27 09:17:21.538586: Forward across 100 steps, 0.416 +/- 0.726 sec / batch\n",
      "2017-10-27 09:17:23.161510: Forward across 100 steps, 0.432 +/- 0.735 sec / batch\n",
      "2017-10-27 09:17:24.601170: Forward across 100 steps, 0.447 +/- 0.740 sec / batch\n",
      "2017-10-27 09:17:26.230900: Forward across 100 steps, 0.463 +/- 0.748 sec / batch\n",
      "2017-10-27 09:17:27.844861: Forward across 100 steps, 0.479 +/- 0.756 sec / batch\n",
      "2017-10-27 09:17:29.634427: Forward across 100 steps, 0.497 +/- 0.765 sec / batch\n",
      "2017-10-27 09:17:31.087297: step 30, duration =1.453\n",
      "2017-10-27 09:17:31.087430: Forward across 100 steps, 0.511 +/- 0.769 sec / batch\n",
      "2017-10-27 09:17:32.512554: Forward across 100 steps, 0.526 +/- 0.773 sec / batch\n",
      "2017-10-27 09:17:33.935068: Forward across 100 steps, 0.540 +/- 0.776 sec / batch\n",
      "2017-10-27 09:17:35.340971: Forward across 100 steps, 0.554 +/- 0.779 sec / batch\n",
      "2017-10-27 09:17:36.733795: Forward across 100 steps, 0.568 +/- 0.781 sec / batch\n",
      "2017-10-27 09:17:38.106085: Forward across 100 steps, 0.582 +/- 0.783 sec / batch\n",
      "2017-10-27 09:17:39.524328: Forward across 100 steps, 0.596 +/- 0.786 sec / batch\n",
      "2017-10-27 09:17:41.006516: Forward across 100 steps, 0.611 +/- 0.788 sec / batch\n",
      "2017-10-27 09:17:42.435280: Forward across 100 steps, 0.625 +/- 0.790 sec / batch\n",
      "2017-10-27 09:17:43.811174: Forward across 100 steps, 0.639 +/- 0.791 sec / batch\n",
      "2017-10-27 09:17:45.189412: step 40, duration =1.378\n",
      "2017-10-27 09:17:45.189554: Forward across 100 steps, 0.652 +/- 0.792 sec / batch\n",
      "2017-10-27 09:17:46.596956: Forward across 100 steps, 0.667 +/- 0.792 sec / batch\n",
      "2017-10-27 09:17:48.020131: Forward across 100 steps, 0.681 +/- 0.793 sec / batch\n",
      "2017-10-27 09:17:49.432976: Forward across 100 steps, 0.695 +/- 0.793 sec / batch\n",
      "2017-10-27 09:17:50.804213: Forward across 100 steps, 0.709 +/- 0.793 sec / batch\n",
      "2017-10-27 09:17:52.186573: Forward across 100 steps, 0.722 +/- 0.793 sec / batch\n",
      "2017-10-27 09:17:53.591108: Forward across 100 steps, 0.736 +/- 0.792 sec / batch\n",
      "2017-10-27 09:17:55.018353: Forward across 100 steps, 0.751 +/- 0.792 sec / batch\n",
      "2017-10-27 09:17:56.438113: Forward across 100 steps, 0.765 +/- 0.791 sec / batch\n",
      "2017-10-27 09:17:57.816358: Forward across 100 steps, 0.779 +/- 0.789 sec / batch\n",
      "2017-10-27 09:17:59.186308: step 50, duration =1.370\n",
      "2017-10-27 09:17:59.186435: Forward across 100 steps, 0.792 +/- 0.788 sec / batch\n",
      "2017-10-27 09:18:00.563075: Forward across 100 steps, 0.806 +/- 0.786 sec / batch\n",
      "2017-10-27 09:18:01.938811: Forward across 100 steps, 0.820 +/- 0.784 sec / batch\n",
      "2017-10-27 09:18:03.312445: Forward across 100 steps, 0.834 +/- 0.781 sec / batch\n",
      "2017-10-27 09:18:04.685630: Forward across 100 steps, 0.847 +/- 0.778 sec / batch\n",
      "2017-10-27 09:18:06.102735: Forward across 100 steps, 0.862 +/- 0.776 sec / batch\n",
      "2017-10-27 09:18:07.522730: Forward across 100 steps, 0.876 +/- 0.773 sec / batch\n",
      "2017-10-27 09:18:08.896842: Forward across 100 steps, 0.889 +/- 0.769 sec / batch\n",
      "2017-10-27 09:18:10.273106: Forward across 100 steps, 0.903 +/- 0.766 sec / batch\n",
      "2017-10-27 09:18:11.645788: Forward across 100 steps, 0.917 +/- 0.762 sec / batch\n",
      "2017-10-27 09:18:13.019388: step 60, duration =1.373\n",
      "2017-10-27 09:18:13.019527: Forward across 100 steps, 0.931 +/- 0.757 sec / batch\n",
      "2017-10-27 09:18:14.392133: Forward across 100 steps, 0.944 +/- 0.753 sec / batch\n",
      "2017-10-27 09:18:15.769779: Forward across 100 steps, 0.958 +/- 0.748 sec / batch\n",
      "2017-10-27 09:18:17.143006: Forward across 100 steps, 0.972 +/- 0.743 sec / batch\n",
      "2017-10-27 09:18:18.515260: Forward across 100 steps, 0.986 +/- 0.737 sec / batch\n",
      "2017-10-27 09:18:19.890740: Forward across 100 steps, 0.999 +/- 0.732 sec / batch\n",
      "2017-10-27 09:18:21.266943: Forward across 100 steps, 1.013 +/- 0.726 sec / batch\n",
      "2017-10-27 09:18:22.653377: Forward across 100 steps, 1.027 +/- 0.719 sec / batch\n",
      "2017-10-27 09:18:24.026854: Forward across 100 steps, 1.041 +/- 0.713 sec / batch\n",
      "2017-10-27 09:18:25.400500: Forward across 100 steps, 1.054 +/- 0.706 sec / batch\n",
      "2017-10-27 09:18:26.772365: step 70, duration =1.372\n",
      "2017-10-27 09:18:26.772512: Forward across 100 steps, 1.068 +/- 0.698 sec / batch\n",
      "2017-10-27 09:18:28.146214: Forward across 100 steps, 1.082 +/- 0.691 sec / batch\n",
      "2017-10-27 09:18:29.517253: Forward across 100 steps, 1.096 +/- 0.683 sec / batch\n",
      "2017-10-27 09:18:30.926004: Forward across 100 steps, 1.110 +/- 0.674 sec / batch\n",
      "2017-10-27 09:18:32.486827: Forward across 100 steps, 1.125 +/- 0.666 sec / batch\n",
      "2017-10-27 09:18:33.900242: Forward across 100 steps, 1.139 +/- 0.657 sec / batch\n",
      "2017-10-27 09:18:35.278777: Forward across 100 steps, 1.153 +/- 0.648 sec / batch\n",
      "2017-10-27 09:18:36.663751: Forward across 100 steps, 1.167 +/- 0.638 sec / batch\n",
      "2017-10-27 09:18:38.044159: Forward across 100 steps, 1.181 +/- 0.627 sec / batch\n",
      "2017-10-27 09:18:39.414299: Forward across 100 steps, 1.195 +/- 0.616 sec / batch\n",
      "2017-10-27 09:18:40.791072: step 80, duration =1.377\n",
      "2017-10-27 09:18:40.791215: Forward across 100 steps, 1.208 +/- 0.604 sec / batch\n",
      "2017-10-27 09:18:42.167904: Forward across 100 steps, 1.222 +/- 0.592 sec / batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-27 09:18:43.545051: Forward across 100 steps, 1.236 +/- 0.580 sec / batch\n",
      "2017-10-27 09:18:44.913258: Forward across 100 steps, 1.250 +/- 0.566 sec / batch\n",
      "2017-10-27 09:18:46.290227: Forward across 100 steps, 1.263 +/- 0.552 sec / batch\n",
      "2017-10-27 09:18:47.660036: Forward across 100 steps, 1.277 +/- 0.538 sec / batch\n",
      "2017-10-27 09:18:49.031489: Forward across 100 steps, 1.291 +/- 0.522 sec / batch\n",
      "2017-10-27 09:18:50.551639: Forward across 100 steps, 1.306 +/- 0.506 sec / batch\n",
      "2017-10-27 09:18:52.220212: Forward across 100 steps, 1.323 +/- 0.490 sec / batch\n",
      "2017-10-27 09:18:53.774994: Forward across 100 steps, 1.338 +/- 0.472 sec / batch\n",
      "2017-10-27 09:18:55.302086: step 90, duration =1.527\n",
      "2017-10-27 09:18:55.302232: Forward across 100 steps, 1.353 +/- 0.453 sec / batch\n",
      "2017-10-27 09:18:56.802731: Forward across 100 steps, 1.368 +/- 0.432 sec / batch\n",
      "2017-10-27 09:18:58.306375: Forward across 100 steps, 1.384 +/- 0.410 sec / batch\n",
      "2017-10-27 09:18:59.762238: Forward across 100 steps, 1.398 +/- 0.386 sec / batch\n",
      "2017-10-27 09:19:01.223163: Forward across 100 steps, 1.413 +/- 0.359 sec / batch\n",
      "2017-10-27 09:19:02.753228: Forward across 100 steps, 1.428 +/- 0.330 sec / batch\n",
      "2017-10-27 09:19:04.175575: Forward across 100 steps, 1.442 +/- 0.297 sec / batch\n",
      "2017-10-27 09:19:05.547029: Forward across 100 steps, 1.456 +/- 0.260 sec / batch\n",
      "2017-10-27 09:19:06.946191: Forward across 100 steps, 1.470 +/- 0.215 sec / batch\n",
      "2017-10-27 09:19:08.321053: Forward across 100 steps, 1.484 +/- 0.156 sec / batch\n",
      "2017-10-27 09:19:12.576817: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:16.694782: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:20.806155: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:24.911428: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:29.005371: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:33.101522: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:37.205858: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:41.292621: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:45.404176: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:49.513800: Forward-backward across 100 steps, 0.000 +/- 0.000 sec / batch\n",
      "2017-10-27 09:19:53.649960: step 0, duration =4.136\n",
      "2017-10-27 09:19:53.650115: Forward-backward across 100 steps, 0.041 +/- 0.412 sec / batch\n",
      "2017-10-27 09:19:57.791638: Forward-backward across 100 steps, 0.083 +/- 0.579 sec / batch\n",
      "2017-10-27 09:20:02.604705: Forward-backward across 100 steps, 0.131 +/- 0.746 sec / batch\n",
      "2017-10-27 09:20:07.355129: Forward-backward across 100 steps, 0.178 +/- 0.876 sec / batch\n",
      "2017-10-27 09:20:12.180097: Forward-backward across 100 steps, 0.227 +/- 0.991 sec / batch\n",
      "2017-10-27 09:20:16.633915: Forward-backward across 100 steps, 0.271 +/- 1.076 sec / batch\n",
      "2017-10-27 09:20:20.877176: Forward-backward across 100 steps, 0.314 +/- 1.146 sec / batch\n",
      "2017-10-27 09:20:25.133507: Forward-backward across 100 steps, 0.356 +/- 1.211 sec / batch\n",
      "2017-10-27 09:20:29.278105: Forward-backward across 100 steps, 0.398 +/- 1.267 sec / batch\n",
      "2017-10-27 09:20:33.601851: Forward-backward across 100 steps, 0.441 +/- 1.325 sec / batch\n",
      "2017-10-27 09:20:37.967468: step 10, duration =4.365\n",
      "2017-10-27 09:20:37.967628: Forward-backward across 100 steps, 0.485 +/- 1.381 sec / batch\n",
      "2017-10-27 09:20:42.208871: Forward-backward across 100 steps, 0.527 +/- 1.430 sec / batch\n",
      "2017-10-27 09:20:46.401270: Forward-backward across 100 steps, 0.569 +/- 1.474 sec / batch\n",
      "2017-10-27 09:20:50.757803: Forward-backward across 100 steps, 0.612 +/- 1.520 sec / batch\n",
      "2017-10-27 09:20:55.115158: Forward-backward across 100 steps, 0.656 +/- 1.564 sec / batch\n",
      "2017-10-27 09:20:59.262514: Forward-backward across 100 steps, 0.697 +/- 1.601 sec / batch\n",
      "2017-10-27 09:21:03.744334: Forward-backward across 100 steps, 0.742 +/- 1.643 sec / batch\n",
      "2017-10-27 09:21:08.225289: Forward-backward across 100 steps, 0.787 +/- 1.683 sec / batch\n",
      "2017-10-27 09:21:13.074265: Forward-backward across 100 steps, 0.836 +/- 1.728 sec / batch\n",
      "2017-10-27 09:21:17.607137: Forward-backward across 100 steps, 0.881 +/- 1.765 sec / batch\n",
      "2017-10-27 09:21:21.949171: step 20, duration =4.342\n",
      "2017-10-27 09:21:21.949333: Forward-backward across 100 steps, 0.924 +/- 1.796 sec / batch\n",
      "2017-10-27 09:21:26.061181: Forward-backward across 100 steps, 0.965 +/- 1.821 sec / batch\n",
      "2017-10-27 09:21:30.165175: Forward-backward across 100 steps, 1.006 +/- 1.845 sec / batch\n",
      "2017-10-27 09:21:34.244032: Forward-backward across 100 steps, 1.047 +/- 1.867 sec / batch\n",
      "2017-10-27 09:21:38.389057: Forward-backward across 100 steps, 1.089 +/- 1.889 sec / batch\n",
      "2017-10-27 09:21:42.479300: Forward-backward across 100 steps, 1.130 +/- 1.910 sec / batch\n",
      "2017-10-27 09:21:46.598078: Forward-backward across 100 steps, 1.171 +/- 1.929 sec / batch\n",
      "2017-10-27 09:21:50.696292: Forward-backward across 100 steps, 1.212 +/- 1.947 sec / batch\n",
      "2017-10-27 09:21:54.807167: Forward-backward across 100 steps, 1.253 +/- 1.964 sec / batch\n",
      "2017-10-27 09:21:58.903314: Forward-backward across 100 steps, 1.294 +/- 1.981 sec / batch\n",
      "2017-10-27 09:22:03.025108: step 30, duration =4.122\n",
      "2017-10-27 09:22:03.025286: Forward-backward across 100 steps, 1.335 +/- 1.996 sec / batch\n",
      "2017-10-27 09:22:07.129814: Forward-backward across 100 steps, 1.376 +/- 2.010 sec / batch\n",
      "2017-10-27 09:22:11.238397: Forward-backward across 100 steps, 1.417 +/- 2.024 sec / batch\n",
      "2017-10-27 09:22:15.357791: Forward-backward across 100 steps, 1.458 +/- 2.036 sec / batch\n",
      "2017-10-27 09:22:19.450902: Forward-backward across 100 steps, 1.499 +/- 2.048 sec / batch\n",
      "2017-10-27 09:22:23.534393: Forward-backward across 100 steps, 1.540 +/- 2.058 sec / batch\n",
      "2017-10-27 09:22:27.638484: Forward-backward across 100 steps, 1.581 +/- 2.068 sec / batch\n",
      "2017-10-27 09:22:31.731101: Forward-backward across 100 steps, 1.622 +/- 2.077 sec / batch\n",
      "2017-10-27 09:22:35.821607: Forward-backward across 100 steps, 1.663 +/- 2.085 sec / batch\n",
      "2017-10-27 09:22:39.917338: Forward-backward across 100 steps, 1.704 +/- 2.092 sec / batch\n",
      "2017-10-27 09:22:44.019461: step 40, duration =4.102\n",
      "2017-10-27 09:22:44.019625: Forward-backward across 100 steps, 1.745 +/- 2.098 sec / batch\n",
      "2017-10-27 09:22:48.112945: Forward-backward across 100 steps, 1.786 +/- 2.104 sec / batch\n",
      "2017-10-27 09:22:52.240486: Forward-backward across 100 steps, 1.827 +/- 2.109 sec / batch\n",
      "2017-10-27 09:22:57.118987: Forward-backward across 100 steps, 1.876 +/- 2.122 sec / batch\n",
      "2017-10-27 09:23:01.628087: Forward-backward across 100 steps, 1.921 +/- 2.130 sec / batch\n",
      "2017-10-27 09:23:06.218457: Forward-backward across 100 steps, 1.967 +/- 2.137 sec / batch\n",
      "2017-10-27 09:23:10.520223: Forward-backward across 100 steps, 2.010 +/- 2.141 sec / batch\n",
      "2017-10-27 09:23:14.681025: Forward-backward across 100 steps, 2.052 +/- 2.141 sec / batch\n",
      "2017-10-27 09:23:18.876374: Forward-backward across 100 steps, 2.094 +/- 2.142 sec / batch\n",
      "2017-10-27 09:23:23.054695: Forward-backward across 100 steps, 2.135 +/- 2.141 sec / batch\n",
      "2017-10-27 09:23:27.166784: step 50, duration =4.112\n",
      "2017-10-27 09:23:27.166946: Forward-backward across 100 steps, 2.176 +/- 2.140 sec / batch\n",
      "2017-10-27 09:23:31.272313: Forward-backward across 100 steps, 2.217 +/- 2.137 sec / batch\n",
      "2017-10-27 09:23:35.373532: Forward-backward across 100 steps, 2.259 +/- 2.133 sec / batch\n",
      "2017-10-27 09:23:39.473032: Forward-backward across 100 steps, 2.299 +/- 2.129 sec / batch\n",
      "2017-10-27 09:23:43.591818: Forward-backward across 100 steps, 2.341 +/- 2.124 sec / batch\n",
      "2017-10-27 09:23:47.694410: Forward-backward across 100 steps, 2.382 +/- 2.118 sec / batch\n",
      "2017-10-27 09:23:51.810506: Forward-backward across 100 steps, 2.423 +/- 2.111 sec / batch\n",
      "2017-10-27 09:23:55.915913: Forward-backward across 100 steps, 2.464 +/- 2.103 sec / batch\n",
      "2017-10-27 09:24:00.237665: Forward-backward across 100 steps, 2.507 +/- 2.097 sec / batch\n",
      "2017-10-27 09:24:04.928509: Forward-backward across 100 steps, 2.554 +/- 2.093 sec / batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-27 09:24:09.640978: step 60, duration =4.712\n",
      "2017-10-27 09:24:09.641169: Forward-backward across 100 steps, 2.601 +/- 2.088 sec / batch\n",
      "2017-10-27 09:24:14.424956: Forward-backward across 100 steps, 2.649 +/- 2.082 sec / batch\n",
      "2017-10-27 09:24:18.820195: Forward-backward across 100 steps, 2.693 +/- 2.072 sec / batch\n",
      "2017-10-27 09:24:22.959489: Forward-backward across 100 steps, 2.734 +/- 2.059 sec / batch\n",
      "2017-10-27 09:24:27.111401: Forward-backward across 100 steps, 2.776 +/- 2.046 sec / batch\n",
      "2017-10-27 09:24:31.478367: Forward-backward across 100 steps, 2.820 +/- 2.032 sec / batch\n",
      "2017-10-27 09:24:35.814985: Forward-backward across 100 steps, 2.863 +/- 2.018 sec / batch\n",
      "2017-10-27 09:24:40.186114: Forward-backward across 100 steps, 2.907 +/- 2.003 sec / batch\n",
      "2017-10-27 09:24:44.585835: Forward-backward across 100 steps, 2.951 +/- 1.987 sec / batch\n",
      "2017-10-27 09:24:49.036969: Forward-backward across 100 steps, 2.995 +/- 1.970 sec / batch\n",
      "2017-10-27 09:24:53.996815: step 70, duration =4.960\n",
      "2017-10-27 09:24:53.996978: Forward-backward across 100 steps, 3.045 +/- 1.956 sec / batch\n",
      "2017-10-27 09:24:58.749784: Forward-backward across 100 steps, 3.092 +/- 1.939 sec / batch\n",
      "2017-10-27 09:25:03.270460: Forward-backward across 100 steps, 3.137 +/- 1.919 sec / batch\n",
      "2017-10-27 09:25:07.848510: Forward-backward across 100 steps, 3.183 +/- 1.898 sec / batch\n",
      "2017-10-27 09:25:12.394614: Forward-backward across 100 steps, 3.229 +/- 1.876 sec / batch\n",
      "2017-10-27 09:25:17.682583: Forward-backward across 100 steps, 3.282 +/- 1.859 sec / batch\n",
      "2017-10-27 09:25:22.304261: Forward-backward across 100 steps, 3.328 +/- 1.834 sec / batch\n",
      "2017-10-27 09:25:26.778966: Forward-backward across 100 steps, 3.373 +/- 1.806 sec / batch\n",
      "2017-10-27 09:25:32.038255: Forward-backward across 100 steps, 3.425 +/- 1.784 sec / batch\n",
      "2017-10-27 09:25:36.977432: Forward-backward across 100 steps, 3.474 +/- 1.757 sec / batch\n",
      "2017-10-27 09:25:41.704414: step 80, duration =4.727\n",
      "2017-10-27 09:25:41.704575: Forward-backward across 100 steps, 3.522 +/- 1.726 sec / batch\n",
      "2017-10-27 09:25:46.212021: Forward-backward across 100 steps, 3.567 +/- 1.692 sec / batch\n",
      "2017-10-27 09:25:51.089476: Forward-backward across 100 steps, 3.616 +/- 1.658 sec / batch\n",
      "2017-10-27 09:25:55.553518: Forward-backward across 100 steps, 3.660 +/- 1.620 sec / batch\n",
      "2017-10-27 09:26:00.169379: Forward-backward across 100 steps, 3.706 +/- 1.580 sec / batch\n",
      "2017-10-27 09:26:04.449047: Forward-backward across 100 steps, 3.749 +/- 1.537 sec / batch\n",
      "2017-10-27 09:26:09.108147: Forward-backward across 100 steps, 3.796 +/- 1.492 sec / batch\n",
      "2017-10-27 09:26:14.306736: Forward-backward across 100 steps, 3.848 +/- 1.449 sec / batch\n",
      "2017-10-27 09:26:18.793085: Forward-backward across 100 steps, 3.893 +/- 1.398 sec / batch\n",
      "2017-10-27 09:26:23.120935: Forward-backward across 100 steps, 3.936 +/- 1.342 sec / batch\n",
      "2017-10-27 09:26:27.374379: step 90, duration =4.253\n",
      "2017-10-27 09:26:27.374539: Forward-backward across 100 steps, 3.978 +/- 1.283 sec / batch\n",
      "2017-10-27 09:26:31.871268: Forward-backward across 100 steps, 4.023 +/- 1.220 sec / batch\n",
      "2017-10-27 09:26:36.543085: Forward-backward across 100 steps, 4.070 +/- 1.153 sec / batch\n",
      "2017-10-27 09:26:41.470403: Forward-backward across 100 steps, 4.119 +/- 1.081 sec / batch\n",
      "2017-10-27 09:26:46.069882: Forward-backward across 100 steps, 4.165 +/- 0.999 sec / batch\n",
      "2017-10-27 09:26:50.460991: Forward-backward across 100 steps, 4.209 +/- 0.908 sec / batch\n",
      "2017-10-27 09:26:55.018848: Forward-backward across 100 steps, 4.255 +/- 0.803 sec / batch\n",
      "2017-10-27 09:26:59.902885: Forward-backward across 100 steps, 4.304 +/- 0.683 sec / batch\n",
      "2017-10-27 09:27:04.445680: Forward-backward across 100 steps, 4.349 +/- 0.529 sec / batch\n",
      "2017-10-27 09:27:09.270116: Forward-backward across 100 steps, 4.397 +/- 0.300 sec / batch\n"
     ]
    }
   ],
   "source": [
    "run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
